{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from pynput.mouse import Button, Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mouse Control\n",
    "mouse = Controller()\n",
    "screen_width, screen_height = pyautogui.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance between two points\n",
    "def calculate_distance(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    return np.abs(np.degrees(radians))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect a single hand for mouse control\n",
    "def detect_single_hand(hand_landmarks, frame):\n",
    "    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    x, y = int(index_finger_tip.x * screen_width), int(index_finger_tip.y / 2 * screen_height)\n",
    "    \n",
    "    # Ensure the mouse position stays within the screen bounds\n",
    "    x = min(max(x, 0), screen_width - 1)\n",
    "    y = min(max(y, 0), screen_height - 1)\n",
    "    pyautogui.moveTo(x, y)\n",
    "\n",
    "    # Extract landmark positions\n",
    "    landmark_list = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "    thumb_index_dist = calculate_distance(landmark_list[4], landmark_list[8]) * 1000\n",
    "\n",
    "    # Left Click\n",
    "    if thumb_index_dist > 50 and calculate_angle(landmark_list[5], landmark_list[6], landmark_list[8]) < 50:\n",
    "        mouse.press(Button.left)\n",
    "        mouse.release(Button.left)\n",
    "        cv2.putText(frame, \"Left Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        time.sleep(0.2)  # Delay to prevent multiple clicks\n",
    "    \n",
    "    # Right Click\n",
    "    elif thumb_index_dist > 50 and calculate_angle(landmark_list[9], landmark_list[10], landmark_list[12]) < 50:\n",
    "        mouse.press(Button.right)\n",
    "        mouse.release(Button.right)\n",
    "        cv2.putText(frame, \"Right Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        time.sleep(0.2)\n",
    "    \n",
    "    # Double Click\n",
    "    elif thumb_index_dist > 50 and all(calculate_angle(landmark_list[i], landmark_list[i+1], landmark_list[i+3]) < 50 for i in [5, 9]):\n",
    "        pyautogui.doubleClick()\n",
    "        cv2.putText(frame, \"Double Click\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "        time.sleep(0.2)\n",
    "    \n",
    "    # Screenshot\n",
    "    elif thumb_index_dist < 50 and all(calculate_angle(landmark_list[i], landmark_list[i+1], landmark_list[i+3]) < 50 for i in [5, 9]):\n",
    "        im1 = pyautogui.screenshot()\n",
    "        label = random.randint(1, 1000)\n",
    "        im1.save(f'my_screenshot_{label}.png')\n",
    "        cv2.putText(frame, \"Screenshot Taken\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam Capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_distance = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Detect hand gestures\n",
    "    if results.multi_hand_landmarks:\n",
    "        if len(results.multi_hand_landmarks) == 1:\n",
    "            detect_single_hand(results.multi_hand_landmarks[0], frame)\n",
    "        \n",
    "        elif len(results.multi_hand_landmarks) == 2:\n",
    "            # Zoom functionality with two hands\n",
    "            hand1 = results.multi_hand_landmarks[0]\n",
    "            hand2 = results.multi_hand_landmarks[1]\n",
    "\n",
    "            # Get center points of both hands\n",
    "            h, w, _ = frame.shape\n",
    "            hand1_center = (int(hand1.landmark[mp_hands.HandLandmark.WRIST].x * w),\n",
    "                            int(hand1.landmark[mp_hands.HandLandmark.WRIST].y * h))\n",
    "            hand2_center = (int(hand2.landmark[mp_hands.HandLandmark.WRIST].x * w),\n",
    "                            int(hand2.landmark[mp_hands.HandLandmark.WRIST].y * h))\n",
    "\n",
    "            distance = calculate_distance(hand1_center, hand2_center)\n",
    "\n",
    "            if prev_distance is not None:\n",
    "                diff = distance - prev_distance\n",
    "                if diff > 20:\n",
    "                    pyautogui.hotkey(\"ctrl\", \"+\")\n",
    "                    cv2.putText(frame, \"Zoom In\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                elif diff < -20:\n",
    "                    pyautogui.hotkey(\"ctrl\", \"-\")\n",
    "                    cv2.putText(frame, \"Zoom Out\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            prev_distance = distance\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture Control\", frame)\n",
    "    # Adding a small delay to avoid the frame freeze\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
